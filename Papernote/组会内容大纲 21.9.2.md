##组会内容大纲拟定

2021.9.2

组会内容：NL2SQL概况

组会时间：2021.9.24 csq

---

####引入

**背景：**

NL-to-SQL，或者Text-to-SQL，将自然语言转化为SQL查询，使非专业人员也访问和查询数据库。

NL2SQL的任务详情，结合具体例子

**回顾：**

结合上次小组成员张廷意在组会的内容回顾

->深度学习在NL2SQL中的应用，很大程度上取决于数据集的推动。

2017年WiKiSQL数据集的特点，早期的方法：seq2SQl,SQLNet等。

2018年Spider数据集的特点：跨域，多表，更加复杂的查询操作，提出了新的挑战。早期的seq2SQL、SQLNet在WikiSQL中表现良好，但在spider上表现不佳。

---

####研究现状：

主要集中在编码、解码、结合预训练等方法做改进。

**预训练：**

背景：2019年Bert模型回顾，也可用于Text2SQL任务。后来出现了RoBerta、GRappa等预训练模型变体。

（思想，回顾）1.论文：《Hybrid Ranking Network for Text-to-SQL》--2020

主要内容：提出HydraNet，引入了Bert模型。在SQL的生成上，采用和SQLNet类似的子任务划分机制。模型结构简单，在WikiSQL上取得较高的准确率。

针对表格的预训练模型：

Bert模型输入为自然语言序列，不太适合表格任务的处理。后续提出了TaBert、Tapas等预训练模型。

（中详）2.论文：《TABERT: Pretraining for Joint Understanding of
Textual and Tabular Data》--ACL 2020

主要内容：提出了TaBert，针对半结构表的预训练模型。训练过程中拓展了Bert的遮罩词训练方法，用于列和单元格遮罩来学习自然语言和表格模式的表示。

（中详）3.论文：《TAPAS: Weakly Supervised Table Parsing via Pre-training》-- ACL 2020

主要内容：提出了TaPas，针对弱监督的表格任务的预训练模型。将整个表格内容输入模型，得到端到端的执行结果。

TaBert和Tapas的优势和局限性对比，比如两者都是针对于单表，TaPas的表格输入大小有明显限制。

后续还提出了GraPPa、TaPex（2021）等预训练模型。

**解码部分：**

以往的方法将decoding部分看作序列生成，但生成的SQL质量不佳或运行出错。

TranX提出用AST来生成SQL的方法：

（详）4.论文：《TRANX: A Transition-based Neural Abstract Syntax Parser for Semantic Parsing and Code Generation》--2018

主要内容：提出了通用语义分析器，针对NL到MR（meaning representation标准含义表示，除了SQL以外，还适用于可执行的编程语言，如Python和Java等）。结合建树的概率模型，将自然语言转换成一系列建树动作，得到抽象语法树AST，再根据用户自定义的函数，将AST转换为可执行语句。

思路很好，适合SQL这类规整的执行语言。

简单补充介绍：语义分析（semantic phrasing）：研究将自然语言转化为标准表示，范畴比NL-to-SQL更广。


（略）5.论文：《IRNet: A General Purpose Deep Residual Regression Framework for Materials Discovery》--2019

主要内容：对AST进一步做了改进。

在执行的结果上，提出用执行引导（EG）来对模型的编码部分进行优化：

（思想）6.论文：《Robust Text-to-SQL Generation with Execution-Guided Decoding》--2018

主要内容：提出了执行引导，以执行一部分程序返回的结果，来指导训练过程中生成质量的SQL查询，广泛适用于各类Text-to-SQL模型。对模型的提升较大，如WiKiSQL排行靠前的方法基本都将EG运用到推理阶段。

**编码部分：**

目前的研究方法在WiKiSQL上已取得了较高的准确率，但在Spider上还存在许多问题，比如多表、跨域等。准确率不够高。

已将预训练模型广泛应用于Text-to-SQL任务上，以达到更好的效果。

Spider的跨域问题，对于当前模型仍具有很大挑战性。而将模型运用到训练集以外的数据库模式中，对于其现实运用十分有必要。

ShadowGNN提出了一个非常有洞见的方法，把数据库模型映射为抽象的图。其抽象和推理的过程和人类类似。

（详）7.论文：《ShadowGNN: Graph Projection Neural Network for Text-to-SQL Parser》-- ACL 2021

主要内容：针对跨域问题，提出ShadowGNN，以抽象和语义级别来处理数据库模式，通过忽略数据库语义项的名称，利用抽象模式在图投影神经网络（GPNN）中获得问题和数据库模式的表示。通过语义无关的表示，利用关系感知转换器（RAT）来提取问题和模式的逻辑链接。最后，用了和IRNet类似的上下文无关语法的SQL解码器。结合了RoBerta预训练模型。在Spider上的准确率较高。

扩展：简单提一下GNN和RATSQL中的相关内容。

同团队在两个月后提出了LGESQL:

（暂未看）8.论文：《LGESQL: Line Graph Enhanced Text-to-SQL Model with Mixed Local and Non-Local Relations》--ACL 2021

在讲ShadowGNN前考虑再加一篇论文。

**其他方法：**

略提，比如结合用户反馈的方法，也是一个在实际运用中可以考虑的思路。

---

####总结：

研究方向、研究内容的回顾

目前还存在的问题，总体是针对数据集带来的挑战在做工作。

还有哪些地方可以做改进？

最后给出参考文献以及链接
