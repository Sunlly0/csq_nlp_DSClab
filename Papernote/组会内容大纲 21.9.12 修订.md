## 组会内容大纲

2021.9.12

组会内容：NL2SQL研究概况

组会时间：2021.9.24 csq

---

#### 引入

**背景：**

NL-to-SQL，或者Text-to-SQL，将自然语言转化为SQL查询，使非专业人员也访问和查询数据库。

NL2SQL的任务详情，结合具体例子：输入为NL问题、数据库表（模式和内容），输出为SQL语句和执行结果。

**回顾：**

结合上次小组成员张廷意在组会的内容回顾

->深度学习在NL2SQL中的应用，很大程度上取决于数据集的推动。

2017年WiKiSQL数据集的特点，早期的方法：seq2SQl,SQLNet等。

2018年Spider数据集的特点：跨域，多表，更加复杂的查询操作，提出了新的挑战。早期的seq2SQL、SQLNet在WikiSQL中表现良好，但在spider上表现不佳。

---

#### 研究现状：

主要集中在编码、解码、结合预训练等方法做改进。

**预训练：**

背景：2019年Bert模型回顾，也可用于Text2SQL任务。

为什么要有预训练：充分提取输入文本的字词句语义信息，为后续的多样的下游任务带来便利。

Bert利用无标签的自由文本，降低训练成本。预训练任务：Mask ML（随机词遮罩），Next Sentence Predict（判断两个句子是否为前后句）。得到训练好的Bert基础模型，进行微调后，可做分类任务、问答任务等。

后来出现了RoBerta、GRappa等预训练模型变体。


（思想，回顾）1.论文：《Hybrid Ranking Network for Text-to-SQL》--2020

主要内容：提出HydraNet，引入了Bert模型。在SQL的生成上，采用和SQLNet类似的子任务划分机制。模型结构简单，在WikiSQL上取得较高的准确率。充分说明将预训练模型引入NL2SQL中能有效提高准确率。

针对表格的预训练模型：

Bert模型输入为自然语言序列，不太适合表格任务的处理。后续提出了TaBert、Tapas等预训练模型。

TableBert:

回顾组员石微微的分享，TableBert。在Bert的基础上，没有改变预训练模型等预训练方式，仅在输入上做了处理，将表格编码成文本序列输入。

两种编码的线性化方法：1.连接：直接将表格按行或按列输入，按行的效果稍微优于按列；2.模版：比如将表的信息结合表头，以xx is xx的形式进行输入。

效果优于Bert，但还面临许多问题，比如表格太大、表示太过僵硬。

（中详）2.论文：《TABERT: Pretraining for Joint Understanding of
Textual and Tabular Data》--ACL 2020

主要内容：提出了TaBert，针对半结构表的预训练模型。从预训练任务和结构化表格编码表示等，改进了Bert模型。

**NL问题和表格模式的编码：**1.创建内容快照，2.线性化内容快照的各行，输入transformer，得到行级编码向量。3.所有行编码对齐，经过垂直自注意力层、池化层，得到每个NL Token和列的表示。

内容快照：提取和NL问题最为相关的K行，作为后续编码列模式的依据。使用n-gram作为相关性的度量。目的：包含比单纯仅用列名更多的信息，同时也避免了将全部表内容输入模型的巨大资源开销。

行线性化：对单元格编码时包含列名、列类型、单元格值信息。

垂直注意力机制：使行与行之间信息流通。

输出：自然语言各toke、列的表示，单元格的表示，用于下游的训练。也输出一个可变长的表T表示，带前缀[CLS]符号，对于多DB表的分析器很有用。


**预训练任务：**拓展了Bert的遮罩词训练方法，用于列和单元格遮罩来学习自然语言和表格模式的表示。

效果：和Bert在两个维度的不同配置（base/large和K=1/K=3），在两个不同数据集（spider,wtq）上的比较。充分说明了TaBert在表格相关任务上（只对NL2SQL任务）带来的提升。

（中详）3.论文：《TAPAS: Weakly Supervised Table Parsing via Pre-training》-- ACL 2020

主要内容：提出了TaPas，针对弱监督的表格任务的预训练模型。将整个表格内容输入模型，得到端到端的执行结果。

TaBert和Tapas的优势和局限性对比，比如两者都是针对于单表，TaPas的表格输入大小有明显限制。

后续还提出了GraPPa、TaPex（2021）等预训练模型。

**解码部分：**

以往的方法将decoding部分看作序列生成，但生成的SQL质量不佳或运行出错。

TranX提出用AST来生成SQL的方法：

（详）4.论文：《TRANX: A Transition-based Neural Abstract Syntax Parser for Semantic Parsing and Code Generation》--2018

主要内容：提出了通用语义分析器，针对NL到MR（meaning representation标准含义表示，除了SQL以外，还适用于可执行的编程语言，如Python和Java等）。结合建树的概率模型，将自然语言转换成一系列建树动作，得到抽象语法树AST，再根据用户自定义的函数，将AST转换为可执行语句。

思路很好，适合SQL这类规整的执行语言。

简单补充介绍：语义分析（semantic phrasing）：研究将自然语言转化为标准表示，范畴比NL-to-SQL更广。


（略）5.论文：《IRNet: A General Purpose Deep Residual Regression Framework for Materials Discovery》--2019

主要内容：对AST进一步做了改进。

在执行的结果上，提出用执行引导（EG）来对模型的编码部分进行优化：

（思想）6.论文：《Robust Text-to-SQL Generation with Execution-Guided Decoding》--2018

主要内容：提出了执行引导，以执行一部分程序返回的结果，来指导训练过程中生成质量的SQL查询，广泛适用于各类Text-to-SQL模型。对模型的提升较大，如WiKiSQL排行靠前的方法基本都将EG运用到推理阶段。

**编码部分：**

目前的研究方法在WiKiSQL上已取得了较高的准确率，但在Spider上还存在许多问题，比如多表、跨域等。准确率不够高。

已将预训练模型广泛应用于Text-to-SQL任务上，以达到更好的效果。

Spider的跨域问题，对于当前模型仍具有很大挑战性。而将模型运用到训练集以外的数据库模式中，对于其现实运用十分有必要。

ShadowGNN提出了一个非常有洞见的方法，把数据库模型映射为抽象的图。其抽象和推理的过程和人类类似。

（详）7.论文：《ShadowGNN: Graph Projection Neural Network for Text-to-SQL Parser》-- ACL 2021

主要内容：针对跨域问题，提出ShadowGNN，以抽象和语义级别来处理数据库模式，通过忽略数据库语义项的名称，利用抽象模式在图投影神经网络（GPNN）中获得问题和数据库模式的表示。通过语义无关的表示，利用关系感知转换器（RAT）来提取问题和模式的逻辑链接。最后，用了和IRNet类似的上下文无关语法的SQL解码器。结合了RoBerta预训练模型。在Spider上的准确率较高。

扩展：简单提一下GNN和RATSQL中的相关内容。

同团队在两个月后提出了LGESQL:

（暂未看）8.论文：《LGESQL: Line Graph Enhanced Text-to-SQL Model with Mixed Local and Non-Local Relations》--ACL 2021

在讲ShadowGNN前考虑再加一篇论文。

**其他方法：**

略提，比如结合用户反馈的方法，也是一个在实际运用中可以考虑的思路。

---

####总结：

研究方向、研究内容的回顾

目前还存在的问题，总体是针对数据集带来的挑战在做工作。

还有哪些地方可以做改进？

最后给出参考文献以及链接
